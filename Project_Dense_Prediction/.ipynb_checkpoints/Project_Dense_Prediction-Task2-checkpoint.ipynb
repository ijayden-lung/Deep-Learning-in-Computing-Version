{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkkGX0S0oO3N"
   },
   "source": [
    "# Project: Dense Prediction: Monocular Depth Estimation and Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/I2rSgxd.png' width=200> <img src='https://i.imgur.com/1oP2EIg.png' width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8w1z-r-IoO3P"
   },
   "source": [
    "# Part 1\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89HRzsUZoO3Q"
   },
   "source": [
    "- In this part of the project, you are tasked to create a model that **estimates depth from a single input image**. The input is an RGB image and the output is a single channel dense depth map where each pixel is the estimated distance from the 'camera sensor' to an object in the scene in real world units (e.g. in meters). Depth from a single image is a fundemental vision task with many useful applications including scene understanding and reconstruction.\n",
    "\n",
    "- You are to develop a convolutional neural network (CNN) that formulates the problem as a regression of the depth map from a single RGB image. \n",
    "\n",
    "- In this section, we provide all the source code needed for loading and evaluating your model.  You will reuse the model in the next section\n",
    "\n",
    "- Your task in this section is to modify the script in order to:\n",
    "    - Define a [UNet](https://arxiv.org/abs/1505.04597) model that takes an RGB image and outputs a single channel depth map. **[25 points]**\n",
    "    - Define an approprate loss function. **[15 points]**\n",
    "    - Tune the model to achieve an RMSE of **0.035** or less on the given validation set. **[25 points]**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Note**: Make sure that your Collab notebook is a GPU instance. Also, the first time you run the training, the instance might crash for exceeding the allocated memory. This is expected behaviour, especially with large batch sizes. Collab will suggest restarting the session and providing instances with larger memory sizes.\n",
    "\n",
    "**Note**: This project is more open-ended than the previous projects. Multiple solutions can be considered _correct_. As there already exist implementations of various deep networks for this task on the interwebs, **plagiarism will NOT be tolerated**. Your code will be judged for similarity against code available online and other students' code. You are expected to justify every design decision when your project is being evaluated.\n",
    "\n",
    "**Note**: The networks you will design/implement will be much larger than what you have previously designed. Please bring hardware concerns to the attention of the [TA](mailto:wamiq.para@kaust.edu.sa). You will need to begin early to test out new ideas/hyperparameters and training will take much longer. Best of luck!\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWbivyPkMiyC"
   },
   "source": [
    "## Downloading Data\n",
    "Run the following cell to download the dataset and extract the zip archive.\n",
    "\n",
    "If you are not running a Linux/Mac machine. Please download the following zip file manually and extract it in the same directory as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "zh9jhy2ZMuwZ",
    "outputId": "69a0b743-3d48-4013-8838-ba15f20d7dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-14 22:00:57--  https://densedepth2019.s3.amazonaws.com/UnrealData256.zip\n",
      "Resolving densedepth2019.s3.amazonaws.com (densedepth2019.s3.amazonaws.com)... 52.217.39.204\n",
      "Connecting to densedepth2019.s3.amazonaws.com (densedepth2019.s3.amazonaws.com)|52.217.39.204|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 800935450 (764M) [application/zip]\n",
      "Saving to: ‘UnrealData256.zip’\n",
      "\n",
      "100%[======================================>] 800,935,450 10.6MB/s   in 3m 50s \n",
      "\n",
      "2020-10-14 22:04:48 (3.32 MB/s) - ‘UnrealData256.zip’ saved [800935450/800935450]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget -nc https://densedepth2019.s3.amazonaws.com/UnrealData256.zip\n",
    "! unzip -nq UnrealData256.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJZ4SQmWoO3R"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are supposed to change the batch_size and learning_rate from their default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "learning_rate = 1\n",
    "workers = 1 # The number of parallel processes used to read data\n",
    "gpu_id = [0] # only modify if you machine has more than one GPU card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Depth_Estimation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xn4D0lbNoO3W"
   },
   "source": [
    "## Data Loader (no tasks required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "U5v0Gou2oO3X",
    "outputId": "ebcc88fc-9abd-45b2-e438-b3c2d16a32c7"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from loaders import prep_loaders\n",
    "    train_loader, valid_loader = prep_loaders('UnrealData256', batch_size=batch_size, workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "U5v0Gou2oO3X",
    "outputId": "ebcc88fc-9abd-45b2-e438-b3c2d16a32c7"
   },
   "outputs": [],
   "source": [
    "# Examine training data\n",
    "%pylab inline\n",
    "import torchvision\n",
    "sample = iter(train_loader).next()\n",
    "print(sample['image'].shape, sample['depth'].shape)\n",
    "figure(figsize=(9,9)); imshow(torchvision.utils.make_grid(sample['image'], padding=0).permute((1, 2, 0)))\n",
    "figure(figsize=(9,9)); imshow(torchvision.utils.make_grid(sample['depth'], padding=0, normalize=True, scale_each=True).permute((1, 2, 0))[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNSSgqhEoO3a"
   },
   "source": [
    "## Model [25 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your model here. The current model is going to perform very poorly on the task. \n",
    "But it will be fast. You are welcome to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "jmclj9BDoO3b",
    "outputId": "a24309e9-c59b-47a3-92c9-f792f1d77581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to train.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.A = nn.Conv2d(3, 1, kernel_size=3, padding=1, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.A(x)\n",
    "    \n",
    "def create_model_gpu():\n",
    "    model = Model()\n",
    "    model = model.cuda()\n",
    "    model = nn.DataParallel(model, device_ids=[g for g in gpu_id])\n",
    "    return model\n",
    "\n",
    "model = create_model_gpu()\n",
    "print('Ready to train.')\n",
    "\n",
    "#model.load_state_dict(torch.load('trained_model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4DTq8InPoO3d"
   },
   "source": [
    "## Loss Function [15 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a loss function that is suitable for the dense regression task.\n",
    "Why will the current loss not work? Submit the answer in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g19R7WBboO3e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from math import exp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def loss_fn(pred_y, y):\n",
    "    return torch.mean(y.sub(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VqhhpdZhoO3h"
   },
   "source": [
    "## Training + Evaluation [25 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the hyperparameters and the architecture to achieve the target RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tHUCEZcCoO3i",
    "outputId": "5dd810fb-86db-4daf-dd1b-bb2fbb5368ca"
   },
   "outputs": [],
   "source": [
    "run_id = 'model_gpu{}_n{}_bs{}_lr{}'.format(gpu_id, epochs, batch_size, learning_rate); print('\\n\\nTraining', run_id)\n",
    "save_path = run_id + '.pkl'\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "class RMSE(object):\n",
    "    def __init__(self):\n",
    "        self.sq_errors = []\n",
    "        self.num_pix = 0\n",
    "        \n",
    "    def get(self):\n",
    "        return np.sqrt(\n",
    "                    np.sum(np.array(self.sq_errors))/self.num_pix\n",
    "                )\n",
    "    \n",
    "    def add_batch(self, pred, target):\n",
    "        sqe = (pred-target)**2\n",
    "        self.sq_errors.append(np.sum(sqe))\n",
    "        self.num_pix += target.size\n",
    "        \n",
    "    def reset(self):\n",
    "        self.sq_errors = []\n",
    "        self.num_pix = 0\n",
    "\n",
    "\n",
    "# Used to keep track of statistics\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.val = 0; self.avg = 0; self.sum = 0; self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "REPORTS_PER_EPOCH = 10\n",
    "ITER_PER_EPOCH = len(train_loader)\n",
    "ITER_PER_REPORT = ITER_PER_EPOCH//REPORTS_PER_EPOCH\n",
    "\n",
    "metrics = RMSE()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Progress reporting\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    N = len(train_loader)\n",
    "    end = time.time()\n",
    "\n",
    "    for i, (sample) in enumerate(train_loader):\n",
    "\n",
    "        # Load a batch and send it to GPU\n",
    "        x = sample['image'].float().cuda()\n",
    "        y = sample['depth'].float().cuda()\n",
    "\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        # Record loss\n",
    "        losses.update(loss.data.item(), x.size(0))\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model).\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        eta = str(datetime.timedelta(seconds=int(batch_time.val*(N - i))))\n",
    "\n",
    "        # Log training progress\n",
    "        if i % ITER_PER_REPORT == 0:\n",
    "            print('\\nEpoch: [{0}][{1}/{2}]\\t' 'Time {batch_time.val:.3f} ({batch_time.sum:.3f})\\t' 'ETA {eta}\\t'\n",
    "             'Training Loss {loss.val:.4f} ({loss.avg:.4f})'.format(epoch, i, N, batch_time=batch_time, loss=losses, eta=eta))\n",
    "        elif i % (ITER_PER_REPORT//50) == 0:\n",
    "            print('.', end='')\n",
    "            \n",
    "        #break # useful for quick debugging        \n",
    "    torch.cuda.empty_cache(); del x, y; gc.collect()\n",
    "    \n",
    "    # Validation after each epoch\n",
    "    model.eval()\n",
    "    metrics.reset()\n",
    "    for i, (sample) in enumerate(valid_loader):\n",
    "        x, y = sample['image'].float().cuda(), sample['depth'].numpy()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x).detach().cpu().numpy()\n",
    "\n",
    "        metrics.add_batch(y_pred, y)\n",
    "        print('_', end='')\n",
    "    print('\\nValidation RMSE {avg_rmse}'.format(avg_rmse=metrics.get()))\n",
    "    \n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print('\\nTraining done. Model saved ({}).'.format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzEZYQv5oO3l"
   },
   "source": [
    "## Visual Test of the Trained Model (no tasks required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WtaiM5ekoO3m",
    "outputId": "efe6fddf-67b1-4536-aaab-c80185a32127"
   },
   "outputs": [],
   "source": [
    "# Load model from disk\n",
    "#model = create_model_gpu()\n",
    "#model.load_state_dict(torch.load('trained_model.pkl'))\n",
    "#model.eval() # set to evaluation mode\n",
    "\n",
    "# Visualize validation sample\n",
    "sample = iter(valid_loader).next()\n",
    "x = sample['image'].float().cuda()\n",
    "y_pred, y = model(x), sample['depth']\n",
    "\n",
    "figure(figsize=(20,20)); imshow(torchvision.utils.make_grid(sample['image'], padding=0).permute((1, 2, 0)))\n",
    "figure(figsize=(20,20)); imshow(torchvision.utils.make_grid(sample['depth'], padding=0, normalize=True, scale_each=True).permute((1, 2, 0))[:,:,0])\n",
    "figure(figsize=(20,20)); imshow(torchvision.utils.make_grid(y_pred.detach().cpu(), padding=0, normalize=True, scale_each=True).permute((1, 2, 0))[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 2\n",
    "\n",
    "## Semantic Segmentation\n",
    "\n",
    "In this part of the project, you will reuse the model you created in the previous part to perform Semantic Segmentation - instead of assigning a real number to each\n",
    "pixel , you will assign it a class.\n",
    "\n",
    "The tasks are as following:\n",
    "- Write a Dataset class that processes the segmentation data. **[10 points]**\n",
    "    - Modify the UNet model that takes an RGB image and now outputs a single channel _label map_\n",
    "    - Define an approprate loss function. **[5 points]**\n",
    "- Tune the model to achieve an mIOU of **0.45** or higher on the given validation set. **[20 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataset [10 points]\n",
    "We are going to use the [PASCAL VOC dataset](https://drive.google.com/drive/folders/1G54WDNnOQecr5T0sEvZcuyme0WT5Qje3?usp=sharing), which is a commonly used benchmark. In order to reduce the\n",
    "computational requirements, you should downsample the dataset to 256x256, similar to the previous project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now you have to implement the Dataset. Look at the file `loaders.py`.\n",
    "\n",
    "The class you will need to emulate is `class ImageDepthDataset(Dataset)`. The class is called `VOCSeg`, and it must _inherit_ from the `Dataset` class,\n",
    "just like the `ImageDepthDataset`.\n",
    "You need to fill in the `__len__` and the `__getitem__` methods.\n",
    "The `__getitem__` method should yield a dict of the RGB image and the labeled segmentation map.\n",
    "\n",
    "Make sure you downsample the image and the labels to 256x256, otherwise the training will take too much time.\n",
    "\n",
    "Make sure that the labels are in the range `0..N-1`, where\n",
    "N is the number of classes - 21 in our case. You can have one special label for unknown regions.\n",
    "\n",
    "We provide the map of RGB to label for convenience in `get_pascal_labels()`. The map should be read as this - if a pixel has color `[0, 0, 0]`, it has label 0. If the color is\n",
    "`[128, 0, 0]`, the label is 1\n",
    "\n",
    "It is also very common to change the RGB range from 0-255 to 0-1 or -1 to 1. Take a look at [torchvision.transforms.ToTensor](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.ToTensor)\n",
    "and [torchvision.transforms.Normalize](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The PASCAL VOC dataset has predefined train/val sets. Make sure your class implementation can take this _split_ as an argument. Now create train/val loaders using the `get_seg_loaders` function (look at `prep_loaders`), and we should be good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "if __name__ == '__main__':\n",
    "    from loaders import get_seg_loaders\n",
    "    train_loader, valid_loader = get_seg_loaders(root_dir='./VOC2012')\n",
    "\n",
    "    # we have read all files\n",
    "    assert len(train_loader.dataset) == 1464\n",
    "    assert len(valid_loader.dataset) == 1449"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You should implement a few more sanity checks - the range of data in the RGB part, the range of data in the label part, whether the dataset returns tensors,\n",
    "whether the labels have the datatype `torch.long` etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modifying the Loss and Architecture [5 points]\n",
    "You will have to some form of surgery on the network you constructed in Part 1.\n",
    "\n",
    "1. The number of channels the last layer predicts must change to the number of classes in the dataset.\n",
    "2. The loss function must change to reflect the fact that we are now performing per-pixel classification. (What loss did you use for classification in Project 1?)\n",
    "3. You might get a CUDA assert error. This means that you have a label higher than the number of channels in the _logits_. This is very common with semantic segmentation, where you might want to label some region unkown as it's label might be under doubt - for example near the edges of objects. Look up how to ignore a certain label with a classification loss.\n",
    "4. Take care of input label and logit sizes. We want predictions to be 256x256 as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### !! \n",
    "### <span style=\"color:red\"> At this point, we highly recommend restarting your notebook for part 2 and beginning modifying/training the  model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "learning_rate = 1\n",
    "workers = 1 # The number of parallel processes used to read data\n",
    "gpu_id = [0] # only modify if you machine has more than one GPU card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from loaders import get_seg_loaders\n",
    "    train_loader, valid_loader = get_seg_loaders(root_dir='./VOC2012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# You can copy the depth model code with modifications here\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        #TODO Make sure you have the right number channels in the last layer\n",
    "        self.A = nn.Conv2d(3, 1, kernel_size=3, padding=1, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.A(x)\n",
    "\n",
    "def create_model_gpu():\n",
    "    model = Model()\n",
    "    model = model.cuda()\n",
    "    model = nn.DataParallel(model, device_ids=[g for g in gpu_id])\n",
    "    return model\n",
    "\n",
    "model = create_model_gpu()\n",
    "print('Ready to train.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def loss_fn(pred_y, y):\n",
    "    #TODO\n",
    "    return torch.mean(y.sub(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training and Evaluation [18 points]\n",
    "Tune the hyperparameters to get the maximum possible score on the PASCAL VOC challenge. \n",
    "And answer the following questions:\n",
    "1. What is the relationship between the _size_ of the class and the IOU How would you quantify this relationship?\n",
    "2. What is the relationship between the number of instances and the IOU? how many times a class exists in an image vs the IOU?\n",
    "3. The segmentation dataset is small. Initialize the weights of the segmentation net with the weights of the trained depth network.\n",
    "4. Which weights can you not transfer?\n",
    "5. Fine tune (ie train with a lower learning rate) the model in 3 for the same number of epochs as the model with a random initialization (or ImageNet initialized weights)\n",
    "6. What trend do you observe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_id = 'seg_model_gpu{}_n{}_bs{}_lr{}'.format(gpu_id, epochs, batch_size, learning_rate); print('\\n\\nTraining', run_id)\n",
    "save_path = run_id + '.pkl'\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "metrics = Metrics(train_loader.dataset.num_classes, train_loader.dataset.class_names)\n",
    "\n",
    "# Used to keep track of statistics\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.val = 0; self.avg = 0; self.sum = 0; self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "REPORTS_PER_EPOCH = 10\n",
    "ITER_PER_EPOCH = len(train_loader)\n",
    "ITER_PER_REPORT = ITER_PER_EPOCH//REPORTS_PER_EPOCH\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Progress reporting\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    N = len(train_loader)\n",
    "    end = time.time()\n",
    "\n",
    "    for i, (sample) in enumerate(train_loader):\n",
    "\n",
    "        # Load a batch and send it to GPU\n",
    "        x = sample['image'].float().cuda()\n",
    "        y = sample['label'].float().cuda()\n",
    "\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Record loss\n",
    "        losses.update(loss.data.item(), x.size(0))\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model).\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        eta = str(datetime.timedelta(seconds=int(batch_time.val*(N - i))))\n",
    "\n",
    "        # Log training progress\n",
    "        if i % ITER_PER_REPORT == 0:\n",
    "            print('\\nEpoch: [{0}][{1}/{2}]\\t' 'Time {batch_time.val:.3f} ({batch_time.sum:.3f})\\t' 'ETA {eta}\\t'\n",
    "             'Training Loss {loss.val:.4f} ({loss.avg:.4f})'.format(epoch, i, N, batch_time=batch_time, loss=losses, eta=eta))\n",
    "        elif i % (ITER_PER_REPORT) == 0:\n",
    "            print('.', end='')\n",
    "\n",
    "        #break # useful for quick debugging\n",
    "    torch.cuda.empty_cache(); del x, y; gc.collect()\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()\n",
    "    metrics.reset()\n",
    "    for i, (sample) in enumerate(valid_loader):\n",
    "        x, y = sample['image'].float().cuda(), sample['label'].numpy()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "            y_pred = torch.argmax(y_pred, dim=1) # get the most likely prediction\n",
    "\n",
    "        metrics.add_batch(y, y_pred.detach().cpu().numpy())\n",
    "        print('_', end='')\n",
    "    print('\\nValidation stats ', metrics.get_table())\n",
    "\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print('\\nTraining done. Model saved ({}).'.format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization  [2 points]\n",
    "Use the `decode_segmap` function to visualize images and their segmentation. The images must be from the validation set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization  [2 points]\n",
    "Use the `decode_segmap` function to visualize images and their segmentation. The images must be from the validation set.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Project_Depth_Estimate_good.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
